{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pandas as pd\n",
    "from hazm import Stemmer ,Lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open CorpusText & StopWords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus_original = pd.read_csv('./FarsEconomyAllCleaned.csv', sep='\\t',index_col='Unnamed: 0')\n",
    "corpus = corpus_original.copy()\n",
    "stopWords = pd.read_csv('./stopWords.txt', sep='\\t',header=None)\n",
    "stopWords = list(stopWords[0])\n",
    "stopWords.append('تر')\n",
    "stopWords.append('ترین')\n",
    "stopWords.append('ها')\n",
    "stopWords.append('های')\n",
    "stopWords.append('ای')\n",
    "\n",
    "# stopWords.head()\n",
    "# corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summery</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بررسی تخلفات واگذاری آلومینیوم المهدی هفته آین...</td>\n",
       "      <td>عضو کمیسیون انرژی مجلس گفت: تخلفات مربوط به جر...</td>\n",
       "      <td>\\nاحمد مرادی نماینده مجلس شورای اسلامی در گفت‌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>پربیننده‌ترین اخبار خبرگزاری فارس در 24ساعت گذ...</td>\n",
       "      <td>غش کردن مردمی که دلار خریده بودند! و سه‌گانه ا...</td>\n",
       "      <td>\\nپربیننده‌ترین اخبار خبرگزاری فارس در روز گذش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شرکت هندی برای جایگزینی نفت ایران به نفوذ شرکا...</td>\n",
       "      <td>نارایا انرژی، یکی از خریداران هندی و بزرگ نفت ...</td>\n",
       "      <td>\\nبه گزارش گروه اقتصاد بین‌الملل فارس به نقل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سیر نزولی قیمت خودرو  با سقوط نرخ دلار آغاز شد</td>\n",
       "      <td>قیمت انواع خودروهای داخلی و خارجی امروز در باز...</td>\n",
       "      <td>\\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، قیمت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>دلایل تاخیر در تحویل خودرو‌ها/ چرا خودروهای پر...</td>\n",
       "      <td>قائم مقام مرکز مطالعات استراتژیک فناوری اطلاعا...</td>\n",
       "      <td>\\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، بعد ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  بررسی تخلفات واگذاری آلومینیوم المهدی هفته آین...   \n",
       "1  پربیننده‌ترین اخبار خبرگزاری فارس در 24ساعت گذ...   \n",
       "2  شرکت هندی برای جایگزینی نفت ایران به نفوذ شرکا...   \n",
       "3     سیر نزولی قیمت خودرو  با سقوط نرخ دلار آغاز شد   \n",
       "4  دلایل تاخیر در تحویل خودرو‌ها/ چرا خودروهای پر...   \n",
       "\n",
       "                                             summery  \\\n",
       "0  عضو کمیسیون انرژی مجلس گفت: تخلفات مربوط به جر...   \n",
       "1  غش کردن مردمی که دلار خریده بودند! و سه‌گانه ا...   \n",
       "2  نارایا انرژی، یکی از خریداران هندی و بزرگ نفت ...   \n",
       "3  قیمت انواع خودروهای داخلی و خارجی امروز در باز...   \n",
       "4  قائم مقام مرکز مطالعات استراتژیک فناوری اطلاعا...   \n",
       "\n",
       "                                                body  \n",
       "0  \\nاحمد مرادی نماینده مجلس شورای اسلامی در گفت‌...  \n",
       "1  \\nپربیننده‌ترین اخبار خبرگزاری فارس در روز گذش...  \n",
       "2  \\nبه گزارش گروه اقتصاد بین‌الملل فارس به نقل ا...  \n",
       "3  \\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، قیمت...  \n",
       "4  \\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، بعد ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus.drop(['date'],axis=1)\n",
    "corpus = corpus[['title','summery','body']]\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Start\n",
    "\n",
    "We want model our document to vector\n",
    "\n",
    "We find 100 important words from our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at first we set weight:\n",
    "- words in title: 3x \n",
    "- words in summary: 2x \n",
    "- words in body: 1x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- set vector dimention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some cleaninc in text for some chars: '\\n' , ':' , '.' , ',' and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_original.copy()\n",
    "def clean(text):\n",
    "    text = text.replace('\\n',' ').\\\n",
    "                replace(':','').\\\n",
    "                replace('.','').\\\n",
    "                replace('،','').\\\n",
    "                replace('/','').\\\n",
    "                replace('فیلم','').\\\n",
    "                replace('+','').\\\n",
    "                replace('»','').\\\n",
    "                replace('«','').\\\n",
    "                replace('(','').\\\n",
    "                replace(')','').\\\n",
    "                replace('\\xa0','').\\\n",
    "                replace('\\u200c',' ')\n",
    "    \n",
    "    text = text.replace('گزارش','').\\\n",
    "                replace('فارس','').\\\n",
    "                replace('نقل','').\\\n",
    "                replace('خبرگزاری','').\\\n",
    "                replace('خبرنگار','')\n",
    "    \n",
    "    \n",
    "    text = text.replace('  ',' ')\n",
    "    t = text.split(' ')\n",
    "    t = [x for x in t if x not in stopWords and\\\n",
    "                           not x.isdigit() and\\\n",
    "                           not '']\n",
    "    return t\n",
    "\n",
    "corpus['title']   = corpus['title'].apply(clean)\n",
    "corpus['summery'] = corpus['summery'].apply(clean)\n",
    "corpus['body']    = corpus['body'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "\n",
    "#inner function\n",
    "stem = lambda x:Stemmer().stem(x)\n",
    "lem = lambda x:Lemmatizer().lemmatize(x)\n",
    "def cbow_adder(x,importance=1):\n",
    "    if x in dictionary.keys():\n",
    "        dictionary[x] += 1*importance\n",
    "    else:\n",
    "        dictionary[x] = 1*importance\n",
    "    return x\n",
    "\n",
    "#outter function\n",
    "cbow_maker     = lambda txt: (list(map(cbow_adder,txt)))\n",
    "cbow_stemmer   = lambda txt: (list(map(stem,txt)))\n",
    "cbow_lemmatize = lambda txt: (list(map(lem,txt)))\n",
    "\n",
    "#start function\n",
    "# corpus.title   = corpus.title.apply(cbow_lemmatize)\n",
    "# print('       ','lemma done!')\n",
    "# corpus.title   = corpus.title.apply(cbow_stemmer)\n",
    "# print('       ','stm done!')\n",
    "corpus.title   = corpus.title.apply(cbow_maker)\n",
    "# print('       ','maker done!')\n",
    "\n",
    "dictionary = {k:v*1.5 for k, v in dictionary.items()}\n",
    "\n",
    "# corpus.summery   = corpus.summery.apply(cbow_lemmatize)\n",
    "# corpus.summery   = corpus.summery.apply(cbow_stemmer)\n",
    "corpus.summery   = corpus.summery.apply(cbow_maker)\n",
    "dictionary = {k:v*2 for k, v in dictionary.items()}\n",
    "\n",
    "# corpus.body   = corpus.body.apply(cbow_lemmatize)\n",
    "# corpus.body   = corpus.body.apply(cbow_stemmer)\n",
    "corpus.body   = corpus.body.apply(cbow_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary\n",
    "di = {\n",
    "    'word':[*dictionary],\n",
    "    'frequency':list(dictionary.values())\n",
    "}\n",
    "cbow = pd.DataFrame.from_dict(di)\n",
    "cbow = cbow.sort_values(by='frequency',ascending=False)\n",
    "cbow = cbow[cbow.word != '']\n",
    "dims = cbow.iloc[:100]\n",
    "# dictionary.clear()\n",
    "# dictionary\n",
    "dims.to_csv('./VectorDim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>آمریکا</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>Nas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1    2\n",
       "546  آمریکا  آمریکا  Nas"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm = pd.read_csv('./PTB_stem_dataset.txt', sep='\\t',header=None)\n",
    "stm[stm[0]== 'آمریکا']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>آمریکا</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>آمریکای</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1  2\n",
       "3068   آمریکا  آمریکا  N\n",
       "3069  آمریکای  آمریکا  N"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = pd.read_csv('./PDTB_lemma_dataset.txt', sep='\\t',header=None)\n",
    "lem[lem[1] == 'آمریکا']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'رفت#رو'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from hazm import Stemmer, Lemmatizer\n",
    ">>> stemmer = Stemmer()\n",
    ">>> stemmer.stem('کتاب‌ها')\n",
    ">>> lemmatizer = Lemmatizer()\n",
    ">>> lemmatizer.lemmatize('می‌روم')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
