{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "import pandas as pd\n",
    "from hazm import Stemmer ,Lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open CorpusText & StopWords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus_original = pd.read_csv('./FarsEconomyAllCleaned.csv', sep='\\t',index_col='Unnamed: 0')\n",
    "corpus = corpus_original.copy()\n",
    "stopWords = pd.read_csv('./stopWords.txt', sep='\\t',header=None)\n",
    "stopWords = list(stopWords[0])\n",
    "stopWords.append('تر')\n",
    "stopWords.append('ترین')\n",
    "stopWords.append('ها')\n",
    "stopWords.append('های')\n",
    "stopWords.append('ای')\n",
    "\n",
    "# stopWords.head()\n",
    "# corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summery</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بررسی تخلفات واگذاری آلومینیوم المهدی هفته آین...</td>\n",
       "      <td>عضو کمیسیون انرژی مجلس گفت: تخلفات مربوط به جر...</td>\n",
       "      <td>\\nاحمد مرادی نماینده مجلس شورای اسلامی در گفت‌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>پربیننده‌ترین اخبار خبرگزاری فارس در 24ساعت گذ...</td>\n",
       "      <td>غش کردن مردمی که دلار خریده بودند! و سه‌گانه ا...</td>\n",
       "      <td>\\nپربیننده‌ترین اخبار خبرگزاری فارس در روز گذش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شرکت هندی برای جایگزینی نفت ایران به نفوذ شرکا...</td>\n",
       "      <td>نارایا انرژی، یکی از خریداران هندی و بزرگ نفت ...</td>\n",
       "      <td>\\nبه گزارش گروه اقتصاد بین‌الملل فارس به نقل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سیر نزولی قیمت خودرو  با سقوط نرخ دلار آغاز شد</td>\n",
       "      <td>قیمت انواع خودروهای داخلی و خارجی امروز در باز...</td>\n",
       "      <td>\\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، قیمت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>دلایل تاخیر در تحویل خودرو‌ها/ چرا خودروهای پر...</td>\n",
       "      <td>قائم مقام مرکز مطالعات استراتژیک فناوری اطلاعا...</td>\n",
       "      <td>\\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، بعد ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  بررسی تخلفات واگذاری آلومینیوم المهدی هفته آین...   \n",
       "1  پربیننده‌ترین اخبار خبرگزاری فارس در 24ساعت گذ...   \n",
       "2  شرکت هندی برای جایگزینی نفت ایران به نفوذ شرکا...   \n",
       "3     سیر نزولی قیمت خودرو  با سقوط نرخ دلار آغاز شد   \n",
       "4  دلایل تاخیر در تحویل خودرو‌ها/ چرا خودروهای پر...   \n",
       "\n",
       "                                             summery  \\\n",
       "0  عضو کمیسیون انرژی مجلس گفت: تخلفات مربوط به جر...   \n",
       "1  غش کردن مردمی که دلار خریده بودند! و سه‌گانه ا...   \n",
       "2  نارایا انرژی، یکی از خریداران هندی و بزرگ نفت ...   \n",
       "3  قیمت انواع خودروهای داخلی و خارجی امروز در باز...   \n",
       "4  قائم مقام مرکز مطالعات استراتژیک فناوری اطلاعا...   \n",
       "\n",
       "                                                body  \n",
       "0  \\nاحمد مرادی نماینده مجلس شورای اسلامی در گفت‌...  \n",
       "1  \\nپربیننده‌ترین اخبار خبرگزاری فارس در روز گذش...  \n",
       "2  \\nبه گزارش گروه اقتصاد بین‌الملل فارس به نقل ا...  \n",
       "3  \\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، قیمت...  \n",
       "4  \\nبه گزارش خبرنگار اقتصادی خبرگزاری فارس، بعد ...  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus.drop(['date'],axis=1)\n",
    "corpus = corpus[['title','summery','body']]\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Start\n",
    "\n",
    "We want model our document to vector\n",
    "\n",
    "We find 100 important words from our corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at first we set weight:\n",
    "- words in title: 3x \n",
    "- words in summary: 2x \n",
    "- words in body: 1x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- set vector dimention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some cleaninc in text for some chars: '\\n' , ':' , '.' , ',' and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus_original.copy()\n",
    "def clean(text):\n",
    "    text = text.replace('\\n',' ').\\\n",
    "                replace(':','').\\\n",
    "                replace('.','').\\\n",
    "                replace('،','').\\\n",
    "                replace('/','').\\\n",
    "                replace('فیلم','').\\\n",
    "                replace('+','').\\\n",
    "                replace('»','').\\\n",
    "                replace('«','').\\\n",
    "                replace('(','').\\\n",
    "                replace(')','').\\\n",
    "                replace('\\xa0','').\\\n",
    "                replace('\\u200c',' ')\n",
    "    \n",
    "    text = text.replace('گزارش','').\\\n",
    "                replace('فارس','').\\\n",
    "                replace('نقل','').\\\n",
    "                replace('خبرگزاری','').\\\n",
    "                replace('خبرنگار','')\n",
    "    \n",
    "    \n",
    "    text = text.replace('  ',' ')\n",
    "    t = text.split(' ')\n",
    "    t = [x for x in t if x not in stopWords and\\\n",
    "                           not x.isdigit() and\\\n",
    "                           not '']\n",
    "    return t\n",
    "\n",
    "corpus['title']   = corpus['title'].apply(clean)\n",
    "corpus['summery'] = corpus['summery'].apply(clean)\n",
    "corpus['body']    = corpus['body'].apply(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-454-9f1a982b8f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#start function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_lemmatize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'       '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lemma done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_stemmer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-454-9f1a982b8f14>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(txt)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcbow_maker\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcbow_stemmer\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcbow_lemmatize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#start function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-454-9f1a982b8f14>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#inner function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcbow_adder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/hazm/Lemmatizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, words_file, verbs_file, joined_verb_parts)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mwords_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwords_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbs_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;34m\"\"\" Return the next decoded line from the input stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size, keepends)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# If size is given, we call read() only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirstline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;31m# If we're at a \"\\r\" read one extra character (which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size, chars, firstline)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# can the request be satisfied from the character buffer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchars\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# we need more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "#inner function\n",
    "stem = lambda x:Stemmer().stem(x)\n",
    "lem = lambda x:Lemmatizer().lemmatize(x)\n",
    "def cbow_adder(x,importance=1):\n",
    "    if x in dictionary.keys():\n",
    "        dictionary[x] += 1*importance\n",
    "    else:\n",
    "        dictionary[x] = 1*importance\n",
    "    return x\n",
    "\n",
    "#outter function\n",
    "cbow_maker     = lambda txt: (list(map(cbow_maker,txt)))\n",
    "cbow_stemmer   = lambda txt: (list(map(stem,txt)))\n",
    "cbow_lemmatize = lambda txt: (list(map(lem,txt)))\n",
    "\n",
    "#start function\n",
    "corpus.title   = corpus.title.apply(cbow_lemmatize)\n",
    "print('       ','lemma done!')\n",
    "corpus.title   = corpus.title.apply(cbow_stemmer)\n",
    "print('       ','stm done!')\n",
    "corpus.title   = corpus.title.apply(cbow_maker)\n",
    "print('       ','maker done!')\n",
    "\n",
    "dictionary = {k:v*1.5 for k, v in dictionary.items()}\n",
    "\n",
    "# corpus.summery   = corpus.summery.apply(cbow_lemmatize)\n",
    "# corpus.summery   = corpus.summery.apply(cbow_stemmer)\n",
    "# corpus.summery   = corpus.summery.apply(cbow_maker)\n",
    "# dictionary = {k:v*2 for k, v in dictionary.items()}\n",
    "\n",
    "# corpus.body   = corpus.body.apply(cbow_lemmatize)\n",
    "# corpus.body   = corpus.body.apply(cbow_stemmer)\n",
    "# corpus.body   = corpus.body.apply(cbow_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/myenv/lib/python3.6/site-packages/pandas/core/ops.py:1167: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid type comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-455-143726bee2e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'frequency'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# dictionary.clear()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/myenv/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid type comparison"
     ]
    }
   ],
   "source": [
    "dictionary\n",
    "di = {\n",
    "    'word':[*dictionary],\n",
    "    'frequency':list(dictionary.values())\n",
    "}\n",
    "cbow = pd.DataFrame.from_dict(di)\n",
    "cbow = cbow.sort_values(by='frequency',ascending=False)\n",
    "cbow = cbow[cbow.word != '']\n",
    "dims = cbow.iloc[:100]\n",
    "# dictionary.clear()\n",
    "# dictionary\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>آمریکا</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>Nas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1    2\n",
       "546  آمریکا  آمریکا  Nas"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stm = pd.read_csv('./PTB_stem_dataset.txt', sep='\\t',header=None)\n",
    "stm[stm[0]== 'آمریکا']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>آمریکا</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>آمریکای</td>\n",
       "      <td>آمریکا</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1  2\n",
       "3068   آمریکا  آمریکا  N\n",
       "3069  آمریکای  آمریکا  N"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = pd.read_csv('./PDTB_lemma_dataset.txt', sep='\\t',header=None)\n",
    "lem[lem[1] == 'آمریکا']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'رفت#رو'"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from hazm import Stemmer, Lemmatizer\n",
    ">>> stemmer = Stemmer()\n",
    ">>> stemmer.stem('کتاب‌ها')\n",
    ">>> lemmatizer = Lemmatizer()\n",
    ">>> lemmatizer.lemmatize('می‌روم')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [بررسی, تخلفات, واگذاری, آلومینیوم, المهدی, هف...\n",
       "1                    [پربیننده, اخبار, , 24ساعت, گذشته, ]\n",
       "2       [شرکت, هندی, جایگزینی, نفت, ایران, نفوذ, شرکای...\n",
       "3        [سیر, نزولی, قیمت, خودرو, سقوط, نرخ, دلار, آغاز]\n",
       "4       [دلایل, تاخیر, تحویل, خودرو, خودروهای, پرمتقاض...\n",
       "5       [آمار, دقیقی, واحدهای, خالی, سکنه, هزار, واحد,...\n",
       "6                     [توافق, مکزیک, کانادا, شغل, آمریکا]\n",
       "7       [روسای, آمریکا, کانادا, پیشبرد, مذاکرات, تجاری...\n",
       "8             [ترکیه, ماه, سپتامبر, هزار, تن, فندق, صادر]\n",
       "9       [سکه, میلیون, هزار, تومان, نزول, قیمت, انواع, ...\n",
       "10      [روسیه, قادر, کمبود, انرژی, بازار, آسیایی, تحر...\n",
       "11      [درصدی, ترانزیت, ریلی, افتتاح, فاز, پایانه, حم...\n",
       "12      [آشکار, مداخله, یهودیان, نوسانات, بازار, ارز, ...\n",
       "13      [مصوبه, مدیریت, بازار, ارز, انتشار, اوراق, مشا...\n",
       "14      [حمایت, پتروشیمی, صنایع, آرد, نان, ایران, مواف...\n",
       "15      [خروج, انگلیس, اتحادیه, اروپا, سرمایه, تویوتا,...\n",
       "16         [توافق, تجاری, نفتا, قیمت, خودرو, آمریکا, برد]\n",
       "17      [اقدامات, بسیج, سازندگی, مقابله, جنگ, اقتصادی۱...\n",
       "18                              [بورس, آسیایی, قرمز, پوش]\n",
       "19      [اروپا, آمادگی, مواجهه, بحران, نظام, مالی, الم...\n",
       "20      [پیشتازی, نفت, دلارعربستان, نتوانست, خواسته, ت...\n",
       "21             [پوتین, حذف, دلار, اقتصاد, روسیه, حمایت, ]\n",
       "22           [آمادگی, شعب, ارزی, بانک, خرید, ارز, مردم, ]\n",
       "23       [وعده, زنگنه, صادرات, گاز, عمان, سال, عملی, نشد]\n",
       "24      [دلالان, نرخ, مردم, نگاه, کنندکاهش, هزار, توما...\n",
       "25      [تعرفه, کالا, پرداخت, مابه, التفاوت, ارز, معاف...\n",
       "26      [جهش, قیمت, موز, سیب, زمینی, رب, گوجه, ماه, شه...\n",
       "27      [بشکه, نفت, دلار, افزایش, قیمت, نفت, علیرغم, خ...\n",
       "28      [میلیارد, تومان, تسهیلات, صندوق, توسعه, ملی, خ...\n",
       "29      [قیمت, خودروهای, داخلی, خارجی, میلیون, تومان, ...\n",
       "                              ...                        \n",
       "1330                           [طالبی, دبیر, بانک, مرکزی]\n",
       "1331    [سالانه, میلیون, مکعب, رسوب, سدها, شودایران, س...\n",
       "1332    [نوآوری, شرکت, ملی, احیای, کارت, سوخت, سرمایۀ,...\n",
       "1333    [صنعت, انرژی, اقتصاد, ایران, تحریم, آمریکا, خس...\n",
       "1334                               [عصبانیت, رهبری, بانک]\n",
       "1335    [نامه, ایران, دوگانه, \"سیاست, اسلامی, اقتصاد, ...\n",
       "1336       [معاون, نظارتی, بانک, مرکزی, حکم, همتی, منصوب]\n",
       "1337                                   [شاخص, بورس, واحد]\n",
       "1338             [فهرست, موتورسیکلت, تولید, شماره, متوقف]\n",
       "1339    [سیب, پرتقال, مرغ, رکورد, بیشترین, افزایش, قیم...\n",
       "1340    [ادامه, کاهش, نرخ, ارز, بازار, ثانویه, تامین, ...\n",
       "1341          [توزیع, میلیون, هزار, قطعه, سکه, مهر, آبان]\n",
       "1342                               [صادرات, شکر, ممنوع, ]\n",
       "1343    [فرصت, میلیون, مشمول, جامانده, سود, سهام, عدال...\n",
       "1344    [بعید, آمریکا, ژاپن, مجوز, واردات, نفت, ایران,...\n",
       "1345              [راننده, تاکسی, تصاویر, گوشی, گوگل, لو]\n",
       "1346    [اختصاص, میلیون, دلار, صندوق, توسعه, ملی, افزا...\n",
       "1347         [جزئیات, طرح, مالیات, عایدی, سرمایه, مسکن, ]\n",
       "1348    [افزایش, برد, شبکه, وای, –, فای, خانگی, دستگاه...\n",
       "1349    [افزایش, گرایش, خرید, لوازم, خانگی, ایرانیحل, ...\n",
       "1350    [فسخ, وکالت, فروش, اسناد, خودرو, ماه, مشمول, م...\n",
       "1351    [پاسخ, تند, وزارت, سازمان, نظام, مهندسی, ساختم...\n",
       "1352    [ظرفیت, تولید, پتروشیمی, مرز, میلیون, تن, گذشت...\n",
       "1353    [توزیع, نوشت, افزار, پوشاک, ایرانی, فروشگاه, ز...\n",
       "1354    [جزئیات, تکمیل, کریدور, شماره, کشور, کردستان, ...\n",
       "1355    [مهمترین, عامل, هوا, فروشی, پمپ, بنزین, طلایی,...\n",
       "1356    [وزارت, صمت, افزایش, قیمت, خودرو, توسط, خودروس...\n",
       "1357            [اعمال, تغییرات, آزمایشی, تازه, توییتر, ]\n",
       "1358    [تصویب, کلیات, طرح, تامین, توزیع, کالای, اساسی...\n",
       "1359           [آغاز, فروش, بلیت, مهرماه, قطار, شهریور, ]\n",
       "Name: title, Length: 1360, dtype: object"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
